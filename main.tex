\documentclass[14pt]{extarticle}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}

\usepackage{booktabs}
\usepackage{multirow}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage{float}

\DeclareMathOperator{\cov}{cov} %Ковариация
\DeclareMathOperator{\med}{med} %Медиана
\DeclareMathOperator{\corr}{\rho} %Коэффициент корреляции
\DeclareMathOperator{\pirs}{r} %Коэффициент корреляции Пирсона
\DeclareMathOperator{\const}{const} %Константа
\DeclareMathOperator{\argmin}{argmin} %Функтор, возвращающий значение параметров по минимизации аргумента
\DeclareMathOperator{\sign}{sign} %Сигнум-функция
\DeclareMathOperator{\normal}{\mathcal{N}} %Нормальное распределение
\DeclareMathOperator{\qdrnt}{r_Q} %Квадрантный коэффициент корреляции
\DeclareMathOperator{\spir}{r_S} %Коэффициент Спирмена

\begin{document}
\pagestyle{empty}
\begin{center}
    Санкт-Петербургский Политехнический Университет Петра Великого
    
    \vspace{0.3cm}
    
    Физико-механический институт

    \vspace{0.3cm}
    
    Высшая школа прикладной математики и вычислительной физики
    
    \vspace{3cm}
    
    {\large\textbf{Отчет по лабораторным работам по №1-4 по математической статистике}}

    \vspace{4.5cm}
    
    Выполнил: \hspace{5.5cm}Андреев Даниил Витальевич
    
    Группа: \hspace{9.5cm}5030102/10101
    
    Преподаватель: \hspace{3.6cm}Баженов Александр Николаевич
    
    \vspace{4cm}
    
    Санкт-Петербург
    
    2024 год
\end{center}

\newpage

\section{Описательная статистика}
\subsection{Постановка задачи}
Для 5 распределений:

\begin{itemize}
    \item Нормальное распределение \(\normal{(x, 0, 1)}\) 
    \item Распределение Коши \(C(x, 0, 1)\) 
    \item Распределение Стьюдента \(t(x, 0, 3)\) 
    \item Распределение Пуассона \(P(k, 10)\) 
    \item Равномерное распределение \(U(x,-\sqrt{3}, \sqrt{3})\) 
\end{itemize}\\
Сгенерировать выборки размером 10, 50, 1000 элементов. Построить на одном рисунке гистограмму и график плотности распределения.

\subsection{Теоретическая справка}

Плотности классических распределений:
\begin{itemize}
    \item Нормальное распределение \(\normal(x, 0,1)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\) (Ф. 1.1)
    \item Распределение Коши \(C(x,0,1)=\frac{1}{\pi (x^2+1)}\) (Ф. 1.2)
    \item Распределение Стьюдента \(t(x,0,3)=\frac{\Gamma(2)(1+\frac{x^2}{3})^{-2}}{\sqrt{3\pi}\Gamma(\frac{3}{2})}\) 
    (Ф. 1.3)
    \item Распределение Пуассона \(P(k, 10)=\frac{e^{-10}10^k}{k!}\) (Ф. 1.4)
    \item Равномерное распределение \(U(x, -\sqrt{3}, \sqrt{3})=\begin{cases} 
    \frac{1}{2\sqrt{3}}&\text{, } |x|\leq\sqrt{3} \\
    0&\text{, } |x|>\sqrt{3} 
\end{cases})\) (Ф. 1.5)
\end{itemize}\\\\
Графически гистограмма строится следующим образом: сначала множество значений, которое может принимать элемент выборки, разбивается на несколько интервалов. Чаще всего эти интервалы берут одинаковыми, но это не является строгим требованием. Эти интервалы откладываются на горизонтальной оси, затем над каждым рисуется прямоугольник. Если все интервалы были одинаковыми, то высота каждого прямоугольника пропорциональна числу элементов выборки, попадающих в соответствующий интервал. Если интервалы разные, то высота прямоугольника выбирается таким образом, чтобы его площадь была пропорциональна числу элементов выборки, которые попали в этот интервал.\\
Построение гистограмм используется для получения эмпирической оценки плотности распределения случайной величины. Они являются хорошим инструментом для исследования неизвестных распределений.

\subsection{Реализация}

Реализовывать гистограммы для этих распределений будем на языке Python3 с использованием пакетов numpy, matplotlib, scipy. \\
Ссылка на Github-репозиторий: \texttt{https://github.com/Highlandet/MathStatisctics-Labs}

\subsection{Результаты}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{hauss.png}
    \caption{Нормальное распределение \(\normal(x, 0, 1)\) (Ф. 1.1)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{cauchy.png}
    \caption{Распределение Коши \(C(x, 0, 1)\) (Ф. 1.2)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{student.png}
    \caption{Распределение Стьюдента \(t(x, 0, 3)\) (Ф. 1.3)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{poisson.png}
    \caption{Распределение Пуассона \(P(k, 10)\) (Ф. 1.4)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{uniform.png}
    \caption{Равномерное распределение \(U (x, -\sqrt{3}, \sqrt{3})\) (Ф. 1.5)}
    \label{fig:enter-label}
\end{figure}

\subsection{Вывод}

Анализ результатов показывает, что чем больше выборка из распределения, тем больше соответствует гистограмма распределения графику плотности распределения графику плотности его распределения. Аналогично: чем больше выборка, тем более заметен характер распределения.

\section{Точечное оценивание характеристик положения и рассеяния}

\subsection{Постановка задачи}

Сгенерировать выборки размером 10, 100, 1000 элементов. Для каждой выборки вычислить следующие статистические характеристики положения данных: \(\overline{x}\), \(\text{med }x\), \(z_R\), \(z_Q\), \(z_{tr}\). Повторить такие вычисления 1000 раз для каждой выборки и найти среднее характеристик положения и их квадратов: \(E(z)=\overline{z}\), вычислить оценку дисперсии по формуле \(D(z)=\overline{z^2}-\overline{z}^2\). Представить полученные данные в виде таблиц

\subsection{Теоретическая справка}

Характеристики положения:
\begin{itemize}
    \item \textbf{\textit{Выборочное среднее:}} \(\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i\)
    \item \textbf{\textit{Выборочная медиана}}: \(\med{x} = \begin{cases} 
    x_{(l+1)}&\text{, } n=2l+1 \\
    \frac{x_{(l)}+x_{(l+1)}}{2}&\text{, } n=2l\end{cases}\)
    \item \textbf{\textit{Полусумма экстремальных выборочных элементов}} \(z_R=\frac{x_{(1)}+x{(n)}}{2}\)
    \item \textbf{\textit{Полусумма квартилей:}} \(z_Q=\frac{z_{1/4}+z_{3/4}}{2}\)   \(\big(z_p=\begin{cases} 
    x_{[np]+1}&\text{, } np\notin\mathbb{Z} \\
    x_{(np)}&\text{, } np\in\mathbb{Z}\end{cases}\big)\)
    \item \textbf{\textit{Усеченное среднее:}} \(z_{tr}=\frac{1}{n-2r}\sum_{i=r+1}^{n-r} x_i, r\approx\frac{n}{4}\)
    \item \textbf{\textit{Среднее характеристик положения:}} \(E(z)=\overline{z}\)
    \item \textbf{\textit{Оценка дисперсии:}} \(D=\overline{z^2}-\overline{z}^2\)
\end{itemize}

\subsection{Реализация}

Для вычисления статических характеристик положения данных будем использовать язык программирования Python3 и следующие библиотеки: numpy, scipy\\\\
Ссылка на Github-репозиторий:\\ \texttt{https://github.com/Highlandet/MathStatisctics-Labs}

\subsection{Результаты и выводы}

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \toprule
        \textbf{Normal: n=10} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 0.01 & 0.01 & -0.02 & 0.02 & 0.02  \\
        \(D(z)\) &  0.09 & 0.14 & 0.52 & 0.11 & 0.40 \\
        \midrule
  	\textbf{Normal: n=100} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 0.00 & 0.00 & -0.01 & 0.00 & -0.02   \\
        \(D(z)\) & 0.01 & 0.02 & 0.48 & 0.12 & 3.50\\
        \midrule
	\textbf{Normal: n=1000} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & -0.00 & 0.00 & 0.03 & -0.01 & -0.03  \\
        \(D(z)\) &  0.00 & 0.00 & 0.52 & 0.13 & 31.52 \\
        \toprule
    \end{tabular}
    \caption{Нормальное распределение \(\normal(x, 0, 1)\)}
    \label{tab:cauchy_t}
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \toprule
        \textbf{Cauchy: n=10} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 28.87 & 2.24 & -0.40 & 0.53 & 72.39  \\
        \(D(z)\) & 4916.34 & 0.33 & 9790.99 & 2072.20 & 28243.54 \\
        \midrule
  	\textbf{Cauchy: n=100} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 7.33 & -0.01 & 0.11 & -0.05 & 96.26    \\
        \(D(z)\) & 25622.14 & 0.02 & 362.93 & 68.03 & 8561101.15 \\
        \midrule
	\textbf{Cauchy: n=1000} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 0.10 & -0.00 & 9.02 & 0.28 & 777.03 \\
        \(D(z)\) & 14268.18 & 0.00 & 118611.91 & 62.71 & 362212066.22 \\
        \toprule
    \end{tabular}
    \caption{Распределение Коши \(C(x, 0, 1)\)}
    \label{tab:cauchy_t}
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \toprule
        \textbf{Student: n=10} & \(\overline{x}\) & med \( x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & -0.00 & 0.01 & 0.01 & -0.01 & -0.02   \\
        \(D(z)\) & 0.26 & 0.17 & 1.24 & 0.33 & 1.21 \\
        \midrule
  	\textbf{Student: n=100} & \(\overline{x}\) & med \( x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 0.01 & 0.00 & -0.02 & -0.03 & 0.02   \\
        \(D(z)\) & 0.03 & 0.02 & 1.66 & 0.44 & 9.63\\
        \midrule
	\textbf{Student: n=1000} & \(\overline{x}\) & med \( x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & -0.00 & 0.00 & 0.04 & -0.03 & 0.28  \\
        \(D(z)\) & 0.00 & 0.00 & 1.34 & 0.39 & 93.70  \\
        \toprule
    \end{tabular}
    \caption{Распределение Стьюдента \(t(x, 0, 3)\)}
    \label{tab:student_t}
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \toprule
        \textbf{Poisson: n=10} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 10.01 & 9.85 & 10.12 & 5.00 & 17.48  \\
        \(D(z)\) & 1.09 & 1.43 & 4.79 & 1.29 & 4.78 \\
        \midrule
  	\textbf{Poisson: n=100} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 9.99 & 9.84 & 9.98 & 5.06 & 127.35     \\
        \(D(z)\) & 0.10 & 0.20 & 4.77 & 1.24 & 32.79 \\
        \midrule
	\textbf{Poisson: n=1000} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & 10.00 & 10.00 & 10.04 & 5.01 & 1251.75 \\
        \(D(z)\) & 0.01 & 0.00 & 5.03 & 1.24 & 300.95 \\
        \toprule
    \end{tabular}
    \caption{Распределение Пуассона \(P(10, k)\)}
    \label{tab:poisson_t}
\end{table}

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \toprule
        \textbf{Uniform: n=10} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & -0.01 & -0.01 & 0.00 & 0.00 & -0.10   \\
        \(D(z)\) & 0.09 & 0.22 & 0.50 & 0.13 & 0.44 \\
        \midrule
  	\textbf{Uniform: n=100} & \(\overline{x}\) & med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & -0.01 & -0.01 & 0.00 & 0.00 & -0.10  \\
        \(D(z)\) & 0.01 & 0.03 & 0.50 & 0.12 & 3.19 \\
        \midrule
	\textbf{Uniform: n=1000} & \(\overline{x}\)& med \(x\) & \(z_R\) & \(z_Q\) & \(z_{tr}\)\\
        \(E(z)\) & -0.00 & -0.00 & 0.02 & -0.01 & 0.01  \\
        \(D(z)\) & 0.00 & 0.00 & 0.47 & 0.12 & 30.21 \\
        \toprule
    \end{tabular}
    \caption{Равномерное распределение \(U(x, -\sqrt{3}, \sqrt{3})\)}
    \label{tab:uniform_t}
\end{table}        

Проанализировав полученные результаты, можно заметить, что для нормального распределения, распределения Стьюдента и равномерного распределения \(E(z)\) и \(D(z)\) для всех характеристик уменьшается с ростом выборки.\\
В таблице характеристик распределения Коши можно выделить аномальные значения, явно превышающие ожидаемые. Такой результат можно объяснить наличием различных выбросов, неопределенностью матожидания и бесконечностью дисперсии СВ, распределенной по данному закону.

\section{Бокс-плот Тьюки}

\subsection{Теоретическая справка}

\textbf{\textit{Боксплот}} (англ. box plot) - график, использующийся в описательной статистике, компактно изображающий одномерное распределение вероятностей. Такой вид диаграммы в удобной форме показывает медиану, нижний и верхний квартили и выбросы. Границами ящика служат первый и третий квартили, линия в середине ящика - медиана. Концы усов - края статистически значимой выборки (без выбросов). Длину "усов" определяют разность первого квартиля и полутора межквартильных расстояний и сумма третьего квартиля и полутора межквартильных расстояний. Формула имеет вид:
\[X_1 = Q_1-\frac{3}{2}(Q_3-Q_1), X_2=Q_3+\frac{3}{2}(Q_3-Q1)\], \\
где \(X_1\) - нижняя граница уса, \(X_2\) - верхняя граница уса, \(Q_1\) - первый квартиль, \(Q_3\) - третий квартиль.

Данные, выходящие за границы усов (выбросы), отображаются на графике в виде маленьких кружков.

\textbf{\textit{Выбросами}} считаются такие величины \(x\), что: 
$\left[ 
      \begin{gathered} 
        x < X_1^T; \\ 
        x > X_2^T, \\ 
      \end{gathered} 
\right.$

\subsection{Постановка задачи}

Сгенерировать выборки размером 20 и 100 элементов. Построить для них боксплот Тьюки.

\subsection{Реализация}

Отрисовывать боксплоты будем на языке Python3 с использованием программных пакетов numpy и matplotlib.\\
Ссылка на Github-репозиторий:\\
\texttt{https://github.com/Highlandet/MathStatisctics-Labs/}

\subsection{Результаты}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{boxplot_hauss.png}
    \caption{Нормальное распределение \(\normal(x, 0, 1)\) (Ф. 1.1)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{boxplot_cauchy.png}
    \caption{Распределение Коши \(C(x, 0, 1)\) (Ф. 1.2)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{boxplot_student.png}
    \caption{Распределение Стьюдента \(t(x, 0, 3)\) (Ф. 1.3)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{boxplot_poisson.png}
    \caption{Распределение Пуассона \(P(k, 10)\) (Ф. 1.4)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{boxplot_histogram.png}
    \caption{Равномерное распределение \(U (x, -\sqrt{3}, \sqrt{3})\) (Ф. 1.5)}
    \label{fig:enter-label}
\end{figure}

\subsection{Выводы}

Боксплот нормального распределения имеет симметричную форму ящика, почти по центру которого располагается медиана.\\
Для распределения Коши наблюдается смещение среднего значения от медианы и аномальные выбросы из-за отсутствия конечного матожидания и дисперсии.\\
При увеличении выборки ящик боксплота распределения Стьюдента смещается (это связано с ненулевым коэффициентом асимметрии при \(n\leq 3\)), и появляется больше выбросов.\\
Для распределения Пуассона боксплот Тьюки может более компактен и симмитричен при увеличении выборки, однако, как и в случае с другими распределениями, при небольших выборках или наличии выбросов наблюдаются некоторые асимметрии (смещен ящик боксплота).\\
Для равномерного распределения с увеличением выборки стремятся поделить в соответствующем процентном соотношении всю длину боксплота - это связано с тем, что равномерное распределение не имеет выбросов.

\section{Доверительные интервалы для параметров нормального распределения}

\subsection{Теоретическая справка}

Промежуток \([\widehat{\theta_1}, \widehat{\theta_2}]\) называется \textbf{\textit{доверительным интервалом для параметра \(\theta\) с уровнем доверия \(\beta\)}} тогда и только тогда, когда \(\mathbb{P}\{\widehat{\theta_1}\leq\theta\leq\widehat{\theta_2}\}\geq\beta\). Под знаком неравенства в выражении выше обычно подразумевают равенство. \(\widehat{\theta_1}\) - оценка нижней границы доверительного интервала, \(\widehat{\theta_2}\) - оценка верхней границы доверительного интервала.\\\\
Дана выборка \((x_i)_{i=1}^n\) нормальной генеральной совокупности. На ее основе строим выборочное среднее \(\overline{x}\) и выборочное СКО \(s\). Параметры \(m\) и \(\sigma\) нормального распределения неизвестны.\\\\
\textbf{Доверительный интервал матожидания \(m\) нормального распределения}\\\\
Доказано, что \textit{статистика Стьюдента} \(T=\frac{\overline{x}-m}{s}\sqrt{n-1}\propto t(x, 0, n-1)\).\\
Пусть \(\alpha\) - \textit{выбранный уровень значимости}, и пусть \(\tau:=t_{1-0.5\alpha}(n-1)\) - соответствующий квантиль распределения Стьюдента, получаемый как результат функции \(F_T^{-1}(x)\), тогда:\\
\[\mathbb{P}\{\overline{x}-\frac{s\tau}{\sqrt{n-1}}<m<\overline{x}+\frac{s\tau}{\sqrt{n-1}}\}=1-\alpha\].\\\\
\textbf{Доверительный интервал СКО \(\sigma\) нормального распределения}\\\\
Доказано, что \(\frac{ns^2}{\sigma^2}\propto\chi^2(n-1)\)
Тогда, аналогично матожиданию:
\[\mathbb{P}\{\frac{s\sqrt{n}}{\sqrt{\chi_{1-0.5\alpha}^2(n-1)}}<\sigma<\frac{s\sqrt{n}}{\sqrt{\chi_{0.5\alpha}^2(n-1)}}\}=1-\alpha\]\\\\
\textbf{Доверительный интервал матожидания m для произвольный генеральной совокупности при большом объеме выборки.}\\\\
В силу ЦПТ:  \(\frac{\overline{x}-M[\overline{x}]}{\sqrt{D[\overline{x}]}}=\frac{\overline{x}-m}{\sigma}\sqrt{n}\propto\normal(x, 0, 1)\). Тогда:
\[\mathbb{P}\bigg{\overline{x}-\frac{su_{1-0.5\alpha}}{\sqrt{n}}<m<\overline{x}+\frac{su_{1-0.5\alpha}}{\sqrt{n}}\bigg}=1-\alpha,\]
где \(u_{1-0.5\alpha}\) - соответствующий квантиль \(\normal(x, 0, 1)\)\\\\
\textbf{Доверительный интервал для СКО \(\sigma\) произвольной генеральной совокупности при большом объеме выборки}\\\\
В силу ЦПТ:  \(\frac{s^2-M[s^2]}{\sqrt{D[s^2]}}\propto N(x, 0, 1)\), тогда:
\[\mathbb{P}\bigg{s(1-0.5\mathcal{U})<\sigma<s(1+0.5\mathcal{U})\bigg}=1-\alpha,\]
где \(\mathcal{U}=u_{1-0.5\alpha}\sqrt{\frac{e+2}{n}}\), а \(e=\frac{m_4}{s^4}-3\) - выборочный эксцесс.
\subsection{Постановка задачи}

Сгенерировать выборки размером 20 и 100 элементов, вычислить параметры положения и рассеяния:
\begin{itemize}
    \item для нормального распределения 
    \item для произвольного распределения
\end{itemize}

\subsection{Реализация}
Реализовывать код по заданию будем на языке Python3, используя библиотеки numpy, scipy и matplotlib.\\
Ссылка на Github-репозиторий: \\
\texttt{https://github.com/Highlandet/MathStatisctics-Labs}

\subsection{Результаты}

\begin{table}[htbp]
    \centering
    \begin{tabular}{|c|c|c|}
        \toprule
         & \(m\) & \(\sigma\)\\
        \toprule
        \textbf{Normal: n=20} & \(0.0341 < m < 0.0997\) & \(1.1499 < \sigma < 1.1985\)\\ 
        \midrule
  	\textbf{Normal: n=100} & \(0.1095 < m < 0.1340\) & \(0.9658 < \sigma < 0.9833\)\\
        \toprule
        \textbf{Random: n=20} & \(0.5120 < m < 0.5305\) & \(0.3171 < \sigma < 0.3236\)\\
        \midrule
        \textbf{Random: n=100} & \(0.4993 < m < 0.5068\) & \(0.2927 < \sigma < 0.2962\)\\
        \toprule
    \end{tabular}
    \caption{Доверительные интервалы для выборочных среднего и дисперсии}
    \label{tab:mus_n_sigmas}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{intervals20normal.jpg}
    \caption{Нормальное распределение \(\normal(x, 0, 1)\), \(n=20\)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{intervals100normal.jpg}
    \caption{Нормальное распределение \(\normal(x, 0, 1)\), \(n=100\)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{intervals20random.jpg}
    \caption{Произвольное распределение, \(n=20\)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{intervals100random.jpg}
    \caption{Нормальное распределение, \(n=100\)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{sigmasnormal.jpg}
    \caption{Доверительные интервалы СКО нормального распределения}
    \label{fig:enter-normal}
    \vspace{1cm}
    \includegraphics[width=0.8\textwidth]{sigmasrandom.jpg}
    \caption{Доверительные интервалы СКО произвольного распределения}
    \label{fig:random}
\end{figure}

\subsection{Выводы}
В обоих случаях при увеличении количества элементов в выборке наблюдается уменьшение как длины доверительного интервала СКО, так и уменьшение ее значения.

\section{Коэффициент корреляции}

\subsection{Теоретическая справка}
Двумерная случайная величина \(\langle X, Y\rangle\) называется \textbf{\textit{распределенной нормально}}, если ее плотность вероятности определяется по формуле:\\ 
\[\normal(x,  y, \overline{x}, \overline{y}, \sigma_x, \sigma_y, \rho)=\frac{\exp\bigg[-\frac{1}{2(1-\rho^2)}\Big(\frac{(x-\overline{x})^2}{\sigma_x^2}-2\rho\frac{(x-\overline{x})(y-\overline{y})}{\sigma_x\sigma_y}+\frac{(y-\overline{y})^2}{\sigma_y^2}\Big)\bigg]}{2\pi\sigma_x\sigma_y\sqrt{1-\rho^2}}\]\\
Компоненты \(X\), \(Y\) двумерной СВ также распределены нормально с матожиданиями \(\overline{x}\), \(\overline{y}\) и СКО \(\sigma_x\), \(\sigma_y\) соответственно. Параметр \(\rho\) называется \textit{коэффициентом корреляции}\\\\
\textbf{\textit{Ковариацией двух СВ \(X\), \(Y\)}} называется величина \[\cov{(X,Y)}=\mathrm{M}[(X-\overline{x})(Y-\overline{y})]\].\\
\textbf{\textit{Коэффициентом корреляции двух СВ \(X\), \(Y\)}} называется величина \[\corr{(X, Y)}=\frac{\cov{(X, Y)}}{\sigma_x\sigma_y}\].\\\\
\textbf{\textit{Выборочным коэффициентом корреляции Пирсона}} называется величина \[\pirs{(X, Y)}=\frac{\cov{(X, Y)}}{s_Xs_Y},\]
где \(s_X^2\), \(s_Y^2\) - выборочные дисперсии \(X\), \(Y\).\\\\
\textbf{\textit{Выборочным квадрантным коэффициентом корреляции}} называется величина \[\qdrnt{(x, y)}=\frac{(n_1+n_3)-(n_2+n_4)}{n},\] где \(n_1, n_2, n_3, n_4\) - количества точек с координатами \((x_i, y_i)^T\) попавшими соответственно в I, II, III, IV квадранты ДСК \(Ox'y'\), где \(x'=x-\med{x}\), \(y'=y-\med{y}\).\\\\
Обозначим ранги, соответствующие значениям переменной \(X\) через \(u\), а ранги, соответствующие значениям переменной \(Y\) - \(v\), тогда \textbf{\textit{выборочным коэффициентом ранговой корреляции Спирмена}} называется величина \[\spir{(x, y)} = \frac{\frac{1}{n}\sum\limits_{i=1}^{n} (u_i-\overline{u})(v-\overline{v})}{\sqrt{\frac{1}{n^2}\sum\limits_{i=1}^{n}(u_i-\overline{u})^2\sum\limits_{j=1}^{n}(v_i-\overline{v})^2}},\] где \(\overline{u}=\overline{v}=\frac{n(n+1)}{2}\) - среднее значение рангов.\\\\
Уравнение проекции эллипса рассеивания на плоскость \(Oxy\) имеет вид \[\frac{(x-\overline{x})^2}{\sigma_x^2}-2\corr{(x,y)}\frac{(x-\overline{x})(y-\overline{y})}{\sigma_x\sigma_y}+\frac{(y-\overline{y})^2}{\sigma_y^2}=\const,\] центр эллипса находится в точке с координатами \((\overline{x}, \overline{y})^T\), оси симметрии составляют с осью \(Ox\) углы \(\alpha\), определяемые равенством \[\alpha=\frac{1}{2}\arctan{\frac{2\corr{(x, y)\sigma_x\sigma_y}}{\sigma_x^2-\sigma_y^2}}+\frac{\pi k}{2}, k\in\mathbb{Z}\]

\subsection{Постановка задачи}
Сгенерировать двумерные выборки размерами 20, 60, 100 для нормального двумерного распределения \(\normal(x, y, 0, 0, 1, 1, \corr)\). Коэффициент корреляции \(\corr\) взять равным 0, 0.5, 0.9. Каждая выборка генерируется 1000 раз и для нее вычисляются среднее значение, среднее значение квадрата и дисперсия коэффициентов корреляции Пирсона, Спирмена и ККК. Повторить все вычисления для смеси нормальных распределений: \[f(x, y)=0.9\cdot\normal(x, y, 0, 0, 1, 1, 0.9)+0.1\cdot\normal(x, y, 0, 0, 10, 10, -0.9),\] изобразить сгенерированные точки на плоскости и нарисовать эллипс равновероятности.

\subsection{Реализация}
Реализовывать будем на языке Python3 с использованием пакетов numpy, matplotlib, scipy. \\
Ссылка на Github-репозиторий: \\
\texttt{https://github.com/Highlandet/MathStatisctics-Labs}

\subsection{Результаты}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline 
        &  & \(\rho=0\) & \(\rho=0.5\) & \(\rho=0.9\) \\
        \hline
        
        & \(\overline{\pirs}\) & -0.002 & 0.478 & 0.896 \\ \cline{2-5} 
        \multirow{3}{*}{N=20} & \(\overline{\pirs^2}\) & 0.050 & 0.261 & 0.806  \\ \cline{2-5} 
        &  \(\sigma_{\pirs}^2\) & 0.050 & 0.032 & 0.002 \\ \cline{1-5} 
        
        & \(\overline{\pirs}\) & 0.001 & 0.498 & 0.896 \\ \cline{2-5} 
        \multirow{3}{*}{N=60} & \(\overline{\pirs^2}\) & 0.017 & 0.257 & 0.894 \\ \cline{2-5} 
        &  \(\sigma_{\pirs}^2\) & 0.017 & 0.009 & 0.001 \\ \cline{1-5} 

        & \(\overline{\pirs}\) & 0.008 & 0.498 & 0.899 \\ \cline{2-5} 
        \multirow{3}{*}{N=100} & \(\overline{\pirs^2}\) & 0.011 & 0.254 & 0.809 \\ \cline{2-5} 
        &  \(\sigma_{\pirs}^2\) & 0.011 & 0.006 & 0.000 \\ \cline{1-5} 
        
        \end{tabular}
    \caption{Коэффициент Пирсона \(\pirs\)}
    \label{tab:my-table}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline 
        &  & \(\rho=0\) & \(\rho=0.5\) & \(\rho=0.9\) \\
        \hline
        
        & \(\overline{\qdrnt}\) & 0.499 & 0.665 & 0.738 \\ \cline{2-5} 
        \multirow{3}{*}{N=20} & \(\overline{\qdnrt^2}\) & 0.260 & 0.452 & 0.738 \\ \cline{2-5} 
        &  \(\sigma_{\qdrnt}^2\) & 0.011 & 0.011 & 0.006 \\ \cline{1-5} 
        
        & \(\overline{\qdrnt}\) & 0.498 & 0.667 & 0.855 \\ \cline{2-5} 
        \multirow{3}{*}{N=60} & \(\overline{\qdrnt^2}\) & 0.252 & 0.448 & 0.734 \\ \cline{2-5} 
        &  \(\sigma_{\qdrnt}^2\) & 0.004 & 0.003 & 0.002 \\ \cline{1-5} 

        & \(\overline{\qdrnt}\) & 0.501 & 0.665 & 0.858 \\ \cline{2-5} 
        \multirow{3}{*}{N=100} & \(\overline{\qdrnt^2}\) & 0.254 & 0.444 & 0.738 \\ \cline{2-5} 
        &  \(\sigma_{\qdrnt}^2\) & 0.011 & 0.002 & 0.001 \\ \cline{1-5} 
        
        \end{tabular}
    \caption{Квадрантный коэффициент \(\qdrnt\)}
    \label{tab:my-table}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline 
        &  & \(\rho=0\) & \(\rho=0.5\) & \(\rho=0.9\) \\
        \hline
        
        & \(\overline{\spir}\) & -0.002 & 0.451 & 0.050 \\ \cline{2-5} 
        \multirow{3}{*}{N=20} & \(\overline{\spir^2}\) & 0.05 & 0.240 & 0.036 \\ \cline{2-5} 
        &  \(\sigma_{\spir}^2\) & 0.05 & 0.036 & 0.004 \\ \cline{1-5} 
        
        & \(\overline{\spir}\) & 0.001 & 0.476 & 0.881 \\ \cline{2-5} 
        \multirow{3}{*}{N=60} & \(\overline{\spir^2}\) & 0.017 & 0.236 & 0.777 \\ \cline{2-5} 
        &  \(\sigma_{\spir}^2\) & 0.017 & 0.010 & 0.001 \\ \cline{1-5} 

        & \(\overline{\spir}\) & 0.007 & 0.477 & 0.887 \\ \cline{2-5} 
        \multirow{3}{*}{N=100} & \(\overline{\spir^2}\) & 0.011 & 0.234 & 0.787 \\ \cline{2-5} 
        &  \(\sigma_{\spir}^2\) & 0.011 & 0.007 & 0.001 \\ \cline{1-5} 
        
        \end{tabular}
    \caption{Ранговый коэффициент Спирмена \(\spir\)}
    \label{tab:my-table}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \toprule
         & \(\pirs\) & \(\qdrnt\) & \(\spir\) \\
        \toprule 
        \(N=20\) & 0.872 & 0.839 & 0.841 \\
        \midrule
        \(N=60\) & 0.876 & 0.841 & 0.858 \\
        \midrule
        \(N=100\) & 0.877 & 0.842 & 0.863 \\
        \toprule
    \end{tabular}
    \caption{Коэффициенты корреляции смеси распределений}
    \label{tab:my_label}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{ellipse20.png}
    \caption{Эллипс равновероятности смеси распределений, \(N=20\)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{ellipse60.png}
    \caption{Эллипс равновероятности смеси распределений, \(N=60\)}
    \label{fig:enter-label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{ellipse100.png}
    \caption{Эллипс равновероятности смеси распределений, \(N=100\)}
    \label{fig:enter-label}
\end{figure}

\subsection{Выводы}

\section{Простая линейная регрессия}
\subsection{Теоретическая справка}
\subsubsection{Модель простой линейной регрессии}
Регрессионную модель описания данных называют \textbf{\textit{простой линейной регрессией}}, если \[y_i=\beta_0+\beta_1x_i+\epsilon_i, i=\overline{1...n},\] где: 
\begin{itemize}
    \item \((x_i)_{i=1}^n\) - значения фактора;
    \item \((y_i)_{i=1}^n\) - наблюдаемые значения отклика;
    \item \((\epsilon_i)_{i=1}^n\) - \textit{гауссовский шум} - независимые, нормально распределенные согласно \(\normal(x, 0, \sigma)\);
    \item \(\beta_0, \beta_1\) - неизвестные параметры, подлежащие оценке.
\end{itemize}\\
В данной модели отклик \(y\) зависит от одного фактора \(x\), и весь разброс экспериментальных точек объясняется только погрешностями наблюдений отклика \(y\). Погрешности результатов измерений \(x\) в этой модели полагают существенно меньшими погрешностей результатов измерений \(y\), так что ими можно пренебречь.
\subsubsection{Метод наименьших квадратов}
При оценивании параметров регрессионной модели используют различные методы. Один из наиболее распространенных подходов заключается в следующем:
\begin{itemize}
    \item Вводится мера рассогласования отклика и регрессионной функции;
    \item Оценки параметров регрессии определяются так, чтобы сделать это рассогласование наименьшим;
\end{itemize}
Достаточно простые расчетные формулы получают при выборе критерия в виде суммы квадратов отклонений значений отклика от значений регрессионной функции: \[Q(\beta_0, \beta_1)=\sum\limits_{i=1}^n\epsilon_i^2=\sum\limits_{i=1}^n(y_i-\beta_0-\beta_1x_i)^2\to\min\limits_{\beta_0,\beta_1\in\mathbb{R}}^{}\]\[\langle\widehat{\beta_0},\widehat{\beta_1}\rangle=\argmin Q(\beta_0, \beta_1)\text{, }\langle\beta_0,\beta_1\rangle\in\mathbb{R}\times\mathbb{R}.\] Задача минимизации критерия \(Q(\beta_0, \beta_1)\) носит название \textbf{\textit{метода наименьших квадратов}}, а оценки \(\widehat{\beta_0}\), \(\widehat{\beta_1}\) - \textit{МНК-оценками}.
\subsubsection{Расчетные формулы МНК-оценок}
МНК-оценки параметров \(\widehat{\beta_0}\), \(\widehat{\beta_1}\) находятся из условия обращения функции \(Q(\beta_0, \beta_1)\) в минимум.\\
Выпишем необходимые условия экстремума: \[
\begin{cases} 
    \frac{\partial Q}{\partial\beta_0}=-2\sum\limits_{i=1}^n(y_i-\beta_0-\beta_ix_i)=0 \\
    \frac{\partial Q}{\partial\beta_1}=-2\sum\limits_{i=1}^n(y_i-\beta_0-\beta_1x_i)x_i=0
\end{cases},
\] оттуда получим систему \[
\begin{cases} 
    \widehat{\beta_0}+\overline{x}\widehat{\beta_1}=\overline{y}\\
    \overline{x}\widehat{\beta_0}+\overline{x^2}\widehat{\beta_1}=\overline{xy}
\end{cases} \text{( }\ast\text{ )},
\]решениями данной системы и стационарными точками \(Q(\beta_0, \beta_1)\) будут \[
\begin{cases} 
    \widehat{\beta_1}=\frac{\overline{xy}-\overline{x}\cdot\overline{y}}{\overline{x^2}-\overline{x}^2} \\
    \widehat{\beta_0}=\overline{y}-\overline{x}\widehat{\beta_1}
\end{cases}.
\] Рассмотрим систему ( \(\ast\) ): \[\det{
\begin{pmatrix}
    1 & \overline{x}\\
    \overline{x} & \overline{x^2}
\end{pmatrix}
}=\frac{1}{n}\sum\limits_{i=1}^n(x_i-\overline{x})^2=s_x^2>0\] если среди \((x_i)_{i=1}^n\) есть различные, что и будем предполагать.\\
Теперь получим вторые производные функционала \(Q(\beta_0, \beta_1)\): \[
\begin{cases}
    \frac{\partial^2Q}{\partial\beta_0^2}=2n \\
    \frac{\partial^2 Q}{\partial\beta_0\partial\beta_1}=2\sum\limits_{i=1}^n=2n\overline{x} \\
    \frac{\partial^2Q}{\partial\beta_1^2}=2\sum\limits_{i=1}^nx_i^2=2n\overline{x^2}
\end{cases}
\] \[\Delta=\frac{\partial^2Q}{\partial\beta_0^2}\cdot\frac{\partial^2Q}{\partial\beta_1^2}-(\frac{\partial^2 Q}{\partial\beta_0\partial\beta_1})^2=4n^2\overline{x^2}-4n^2\overline{x}^2=4n^2s_x^2>0,\] что говорит о нахождении минимума функционала \(Q\) в точке \((\beta_0, \beta_1)^T\).
\subsubsection{Робастные оценки коэффициентов линрегрессии}
\textbf{\textit{Робастность метода}} - устойчивость метода по отношению к наличию в данных редких, но больших по величине, выбросов. Робастость оценок коэффициентов линейной регрессии можно обеспечить различными способами, например \textit{методом наименьших модулей}: \[\sum\limits_{i=1}^n|y_i-\beta_0-\beta_1x_i|\to\min\limits_{\beta_0,\beta_1\in\mathbb{R}}^{}.\]
Рассмотрим простейшую робастную альтернативу МНК-оценкам линейной регрессии:\[
\begin{cases}
    \beta_1=\frac{\overline{xy}-\overline{x}\overline{y}}{\overline{x^2}-\overline{x}^2}=\pirs{(x, y)}\frac{s_x}{s_y}\\
    \beta_0=\overline{y}-\overline{x}\widehat{\beta_1}
\end{cases} \iff
\begin{bmatrix}
    \overline{x}\mapsto\med{x} \\
    \overline{y}\mapsto\med{y} \\
    s_x\mapsto q_x^{\ast}\\
    s_y\mapsto q_y^{\ast}\\
\end{bmatrix} \iff
\begin{cases}
    \widehat{\beta_{1R}}=r_Q\frac{q_y^{\ast}}{q_x^{\ast}}\\
    \widehat{\beta_{0R}}=\med{y}-\widehat{\beta_{1R}}\med{x}
\end{cases},
\] где:
\begin{itemize}
    \item \(r_Q=\frac{1}{n}\sum\limits_{i=1}^n\sign{(x_i-\med{x})}\sign{(y_i-\med{y})}\)\\
    \item \(q_y^{\ast}=\frac{y_{(j)}-y_{(l)}}{k_q(n)}\), \(q_x^{\ast}=\frac{x_{(j)}-x_{(l)}}{k_q(n)}\)\\
    \item \(l=
    \begin{cases}
        \lfloor\frac{n}{4}\rfloor\text{,   }\frac{n}{4}\notin\mathbb{Z}\\
        \frac{n}{4}\text{, }\frac{n}{4}\in\mathbb{Z}
    \end{cases}, j=n-l+1.
    \)
\end{itemize}
Уравнение регрессии принимает вид \(y=\widehat{\beta_{0R}}+\widehat{\beta_{1R}}x\text{ ( }\ast\text{ )}\).\\
Статистики выборочной медианы и интерквартильной широты обладают робастными свойствами в силу того, что основаны на центральных порядковых статистиках, малочувствительных к большим по величине выбросам в данных. Статистика выборочного знакового коэффициента корреляции робастна, так как \(\sign{x}\) чувствительна не к величине, а только к знаку. Отсюда оценка прямой регрессии обладает очевидными свойствами устойчивости к выбросам по \(y\), но является довольно грубой.
\subsection{Постановка задачи}
Найти МНК-оценки коэффициентов линейной регрессии вида \(y_i=a+bx_i+\epsilon_i\), используя 20 точек на отрезке \([-1.8, 2]\) с равномерным шагом \(0.2\), \(\epsilon_i\propto\normal(x, 0, 1)\). В качестве эталона взять \(y_i=2+2x_i+\epsilon_i\). При построении МНК-оценок коэффициентов использовать два критерия:
\begin{enumerate}
    \item наименьших квадратов: \(Q_2(a, b)=\sum\limits_{i=1}^n(y_i-b-ax_i)^2\to\min\limits_{a, b\in\mathbb{R}}^{}\);\\
    \item наименьших модулей: \(Q_1(a, b)=\sum\limits_{i=1}^n|y_i-b-ax_i|\to\min\limits_{a, b\in\mathbb{R}}^{}.\)
\end{enumerate}
Проделать то же самое для выборки, у которой в значения \(y_1\), \(y_{20}\) вносятся возмущения \(10\) и \(-10\).

\subsection{Реализация}
Реализовывать гистограммы для этих распределений будем на языке Python3 с использованием пакетов numpy, scipy. \\
Ссылка на Github-репозиторий: \\
\texttt{https://github.com/Highlandet/MathStatisctics-Labs}

\subsection{Результаты}
Оценки для невозмущенной выборки:
\[\text{МНК: } \widehat{a} = 1.502, \widehat{b} = 1.878\]
\[\text{МНМ: } \widehat{a} = 1.561, \widehat{b} = 1.706\]
\\
Оценки для возмущенной выборки:
\[\text{МНК: } \widehat{a} = 0.074, \widehat{b} = 2.021\]
\[\text{МНМ: } \widehat{a} = 1.417, \widehat{b} = 1.803\]

\subsection{Выводы}

\end{document} 
